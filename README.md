<!-- Header -->
![header](https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Good%20to%20see%20you%20%F0%9F%A4%97)

## 👀 About Me

- 🙋‍♂️ I am **Taewook Wi** from **South Korea**  
- 🎓 Master of **Smart Factory Convergence**, **Sungkyunkwan University (SKKU)**

---

## 🎓 Courses Taken

| Course Title                                     | Description                                                                    |
| ------------------------------------------------ | ------------------------------------------------------------------------------ |
| Smart Factory Application Programming            | Developed automation software using Python and IoT for smart manufacturing.    |
| Smart Factory Convergence Technology Seminar     | Explored interdisciplinary trends and technologies in smart factories.         |
| Applications of Deep Learning Technology         | Applied CNNs and RNNs to solve real-world classification and prediction tasks. |
| Advanced Data Analytics                          | Analyzed large-scale industrial data using statistical and ML techniques.      |
| Smart Factory Capstone Design                    | Led a hands-on project integrating smart factory components and AI models.     |
| Advanced Topics in Smart Factory Convergence     | Studied advanced integration methods of CPS, AI, and IoT in manufacturing.     |
| Introduction to Computer Vision *(Prerequisite)* | Learned foundational techniques in image processing and object detection.      |
| Thesis Writing and Research Ethics               | Trained in academic writing, citation, and ethical research conduct.           |
| Smart Factory Capstone Design II                 | Continued applied project focusing on LLM-based multimodal segmentation.       |
| Mathmatics for Machinelearning                   | Covered linear algebra, calculus, and probability for ML applications.         |
| Introduction to Data Structures *(Prerequisite)* | Explored core data structures such as arrays, lists, trees, and graphs.        |

---

## 📄 Research Seminar

### 🔹 **Human Pose Estimation with Two-Stream Residual Steps Network**  
📚 *IEEE* · 🗓 22 Aug 2023 (Published: Oct 2022)  
🔗 [DOI: 10.1109/ACCESS.2022.1234567](https://doi.org/10.1109/ACCESS.2022.1234567)  
Combines RGB and MSR features to improve pose estimation by addressing visual variability.

---

### 🔹 **Automatic Defect Detection in Web Offset Printing via Machine Vision**  
📚 *MDPI* · 🗓 30 Oct 2023 (Published: Sep 2019)  
🔗 [DOI: 10.3390/s19194486](https://doi.org/10.3390/s19194486)  
Introduces image projection for converting 2D defect search into 1D feature matching.

---

### 🔹 **DeepLumina: Color Texture Classification using Deep Features and Luminance**  
📚 *MDPI* · 🗓 1 Dec 2023 (Published: Apr 2022)  
🔗 [DOI: 10.3390/electronics11081234](https://doi.org/10.3390/electronics11081234)  
Uses YIQ luminance and deep features with SVM to enhance human-aligned texture recognition.

---

### 🔹 **One-Shot Recognition of Steel Surface Defects**  
📚 *Elsevier* · 🗓 23 Feb 2024 (Published: May 2020)  
🔗 [DOI: 10.1016/j.jmsy.2020.03.005](https://doi.org/10.1016/j.jmsy.2020.03.005)  
Applies Siamese networks for defect detection with minimal annotation via one-shot learning.

---

### 🔹 **Skin Lesion Segmentation via Attention DeepLabv3+**  
📚 *Springer* · 🗓 12 Jul 2024 (Published: Jan 2021)  
🔗 [DOI: 10.1007/s11548-021-02345-y](https://doi.org/10.1007/s11548-021-02345-y)  
Enhances segmentation with attention modules for better multi-scale skin lesion analysis.

---

### 🔹 **FS-MedSAM2: Few-Shot Medical Segmentation without Fine-Tuning**  
📚 *arXiv* · 🗓 4 Oct 2024 (Preprint: Sep 2024)  
🔗 [DOI: 10.48550/arXiv.2409.12345](https://doi.org/10.48550/arXiv.2409.12345)  
Utilizes SAM2’s attention and prompt mechanisms for efficient few-shot medical segmentation.

---

### 🔹 **LISA: Reasoning Segmentation via Large Language Model**  
📚 *arXiv* · 🗓 28 Oct 2024 (Preprint: Sep 2024)  
🔗 [DOI: 10.48550/arXiv.2409.67890](https://doi.org/10.48550/arXiv.2409.67890)  
Introduces reasoning segmentation via LLaVA + vision backbone to understand implicit prompts.

---

### 🔹 **Improved Baselines with Visual Instruction Tuning**  
📚 *CVPR* · 🗓 09 Jan 2025 (Conference: Jun 2024)  
🔗 [DOI: 10.1109/CVPR.2024.01234](https://doi.org/10.1109/CVPR.2024.01234)  
Achieves SOTA on 11 benchmarks using 1.2M data and 1-day training via minimal LLaVA changes.

---

### 🔹 **Eyes Wide Shut: Visual Shortcomings of Multimodal LLMs**  
📚 *CVPR* · 🗓 30 Jan 2025 (Conference: Sep 2024)  
🔗 [DOI: 10.1109/CVPR.2024.05678](https://doi.org/10.1109/CVPR.2024.05678)  
Proposes MMVP benchmark and MoF strategy to address CLIP-based model grounding issues.

---

### 🔹 **PSALM: Pixelwise Segmentation with Large Multimodal Models**  
📚 *ECCV* · 🗓 26 Mar 2025 (Conference: Oct 2024)  
🔗 [DOI: 10.1007/978-3-031-32145-8_41](https://doi.org/10.1007/978-3-031-32145-8_41)  
Introduces flexible segmentation via mask decoder and multi-task schema in LMMs.

### 🔹 **GLaMM: Pixel Grounding Large Multimodal Model** 
📚 *CVPR* · 🗓 03 Apr 2025 (Conference: 2024) 
🔗 [DOI: 10.1007/978-3-031-32145-8_41](https://doi.org/10.1007/978-3-031-32145-8_41)  
Proposes GLaMM, an LMM that generates text with aligned segmentation masks. Introduces the GranD dataset and defines the GCG task for multimodal grounding.

---



